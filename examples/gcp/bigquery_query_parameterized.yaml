flow:
  name: bigquery_query_parameterized
  require_leader_election: true
  tasks:

    # Run this task on specified intervals to fetch completed orders.
    - generate:
        name: generate_jobs
        interval: 300s

    # BigQuery query with parameterized SQL for SQL injection protection.
    # Parameters are type-safe and properly escaped by BigQuery client.
    # Results are returned as Arrow RecordBatch for efficient columnar processing.
    #
    # This example demonstrates loading SQL from an external resource file.
    # The query is loaded from "resources/queries/fetch_completed_orders.sql"
    # where "resources/" is the base path configured in config.yaml.
    #
    # Benefits of external SQL files:
    # - Keep complex SQL separate from configuration
    # - Enable SQL syntax highlighting in editors
    # - Easier to maintain and version control large queries
    # - Support SQL file reuse across multiple flows
    - gcp_bigquery_query:
        name: fetch_completed_orders
        credentials_path: /etc/gcp/credentials.json
        project_id: my-project-id
        query:
          resource: "queries/fetch_completed_orders.sql"
        parameters:
          status: "completed"
          start_date: "2024-01-01"
        max_results: 10000
        timeout: "1m"

    # Convert Arrow RecordBatch to JSON format for downstream processing.
    - convert:
        name: arrow_to_json
        target_format: json

    # Split JSON array into individual row events for per-record processing.
    - iterate:
        name: split_rows

    # Output individual row events to console for debugging and monitoring.
    - log:
        name: log
        level: info
        structured: false
